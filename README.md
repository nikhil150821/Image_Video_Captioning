
# ğŸ–¼ï¸ğŸ¥ Unified Image & Video Captioning App

This is a full-stack deep learning application that generates natural language captions for both **images** and **videos** using a unified ResNet50 + LSTM model.

The project includes:
- ğŸ§  Unified deep learning model (ResNet50 + LSTM)
- ğŸ“¦ Dataset processing for Flickr8k and MSR-VTT
- ğŸš€ FastAPI backend with SQLite DB
- ğŸŒ React + Tailwind frontend
- ğŸ§  Inference for uploaded media (image/video)
- ğŸŒ‰ Full integration with preview, animation & caption rendering

---

## ğŸ“ Project Structure

```
Image_Video_Captioning/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                # FastAPI backend with endpoints for image/video captioning
â”‚   â”œâ”€â”€ inference.py           # Inference logic for generating captions
â”‚   â”œâ”€â”€ database.py            # SQLite setup & MediaCaption table
â”‚   â”œâ”€â”€ uploads/               # Stores uploaded files temporarily
â”‚   â””â”€â”€ media_captions.db      # SQLite database file
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html             # Main page
â”‚   â”œâ”€â”€ App.jsx                # React entry with routes
â”‚   â”œâ”€â”€ components/            # Header, Footer, Predict, Error, etc.
â”‚   â””â”€â”€ styles/                # Custom Tailwind/CSS
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ image_data_processing.ipynb
â”‚   â”œâ”€â”€ video_data_processing.ipynb
â”‚   â”œâ”€â”€ vocab.ipynb
â”‚   â””â”€â”€ update_training.ipynb
â”œâ”€â”€ checkpoints/               # Trained model checkpoint (ResNet50-LSTM)
â”œâ”€â”€ README.md                  # â† You're here
```

---

## ğŸ§  Model Summary

The core model architecture consists of:
- **Encoder**: Pretrained ResNet50 (extract image or frame features)
- **Decoder**: LSTM for sequence generation
- Supports both image and video inputs using shared architecture.

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/nikhil150821/Image_Video_Captioning.git
cd Image_Video_Captioning
```

---

### 2ï¸âƒ£ Backend Setup (FastAPI)
```bash
cd backend
pip install -r requirements.txt
# or install manually
pip install fastapi uvicorn sqlalchemy python-multipart opencv-python torch torchvision
uvicorn main:app --reload
```
FastAPI will run at: [http://localhost:8000](http://localhost:8000)

---

### 3ï¸âƒ£ Frontend Setup (React + Vite)
```bash
cd frontend
npm install
npm run dev
```
React frontend will run at: [http://localhost:5173](http://localhost:5173)

---

### 4ï¸âƒ£ Model Training (Optional - already trained)
Inside `/model`, youâ€™ll find three Jupyter Notebooks:
- `image_data_processing.ipynb`: Prepares image data (Flickr8k)
- `video_data_processing.ipynb`: Prepares video data (MSR-VTT)
- `update_training.ipynb`: Trains the shared ResNet50 + LSTM model

---

## ğŸ’¡ Features

- Upload **image** or **video**
- Real-time preview with dimension fitting
- Animated loading screen (â³ flip)
- Redirect to `/predict` with content & caption
- Stores caption data in SQLite
- Clean UI with header, footer, error page

---

## ğŸ“¦ Datasets Used

- **Flickr8k** â€” for image captioning
- **MSR-VTT** â€” for video captioning (frame-based)

---

## ğŸ Demo (Local)

1. Run backend with:
```bash
uvicorn main:app --reload
```

2. Run frontend:
```bash
npm run dev
```

3. Open: [http://localhost:5173](http://localhost:5173)
   - Upload image/video â†’ See preview â†’ Click "Predict" â†’ Get caption.

---

## ğŸ“Œ TODO (Optional Improvements)
- Add authentication & user history
- Add drag-and-drop upload
- Deploy to Vercel + Railway or Render

---

## ğŸ§‘â€ğŸ’» Author

**Nikhil**  
B.Tech CSE - Data Analytics  
GitHub: [@nikhil150821](https://github.com/nikhil150821)

---
