
# ğŸ–¼ï¸ğŸ¥ Unified Image & Video Captioning App

This is a full-stack deep learning application that generates natural language captions for both **images** and **videos** using a unified ResNet50 + LSTM model.

The project includes:
- ğŸ§  Unified deep learning model (ResNet50 + LSTM)
- ğŸ“¦ Dataset processing for Flickr8k and MSR-VTT
- ğŸš€ FastAPI backend with SQLite DB
- ğŸŒ React + Tailwind frontend
- ğŸ§  Inference for uploaded media (image/video)
- ğŸŒ‰ Full integration with preview, animation & caption rendering

---

## ğŸ“ Project Structure

Image_Video_Captioning/
â”‚
â”œâ”€â”€ captioning-app/                      # Full-stack application (FastAPI + React)
â”‚   â”œâ”€â”€ backend/                         # Backend: FastAPI + SQLite + Inference
|   |   â”œâ”€â”€ vstatic/                     #
â”‚   â”‚   â”œâ”€â”€ static/                      # trained models for image & video
|   |   â”œâ”€â”€ uploads/                     # Uploaded files (temporarily stored)
â”‚   â”‚   â”œâ”€â”€ utils/                 
â”‚   â”‚   |   â”œâ”€â”€image_util.py             #
â”‚   â”‚   |   â””â”€â”€video_util.py             #
â”‚   â”‚   â”œâ”€â”€ main.py                      # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ inference.py                 # Unified image/video captioning logic
â”‚   â”‚   â”œâ”€â”€ database.py                  # SQLite setup and MediaCaption table
â”‚   â”‚   â”œâ”€â”€ model.py                     # Refernce model architecture
â”‚   â”‚   â”œâ”€â”€ test_conn.py                 # simple setup to check database connection
â”‚   â”‚   â””â”€â”€ media_captions.db            # SQLite database
â”‚   â”‚
â”‚   â”‚
â”‚   â””â”€â”€ frontend/src/                    # Frontend: React + Tailwind CSS
|       â”œâ”€â”€ assets/                      # used logo,images
â”‚       â”œâ”€â”€ components/                  # Header, Footer, UploadForm , Uploadpreview , Error components
â”‚       |   â”œâ”€â”€ header.jsx
â”‚       |   â”œâ”€â”€ footer.jsx
|       |   â”œâ”€â”€ Uploadform.jsx
|       |   â””â”€â”€ Uploadpreview.jsx
â”‚       â”œâ”€â”€ pages/                       # 
â”‚       |   â”œâ”€â”€ index.jsx
|       |   â””â”€â”€ predict.jsx
â”‚       â”œâ”€â”€ App.jsx                      # Entry point with routing
â”‚       â”œâ”€â”€ main.jsx                      
â”‚       â”œâ”€â”€ index.css                    # User modified css
â”‚       â””â”€â”€ app.css                      # CSS or Tailwind configurations
â”‚
â”‚  
â”‚
â”œâ”€â”€ flickr8kdata/                        # Flickr8k dataset folder (images + captions)
â”œâ”€â”€ msrvttdata/                          # MSR-VTT video dataset (videos + captions)
â”œâ”€â”€ reports/                             # Reports, visualizations, logs
â”‚
â”œâ”€â”€ image_data_processing.ipynb          # Preprocessing images & captions
â”œâ”€â”€ video_data_processing.ipynb          # Frame sampling, video caption prep
â”œâ”€â”€ vocab.ipynb                          # Vocabulary creation from captions
â”œâ”€â”€ uinified_model_training.ipynb        # Unified model training (ResNet50 + LSTM)
â”œâ”€â”€ checkpoints/                         # Trained model checkpoints
â””â”€â”€ README.md                            # â† This file


---

## ğŸ§  Model Summary

The core model architecture consists of:
- **Encoder**: Pretrained ResNet50 (extract image or frame features)
- **Decoder**: LSTM for sequence generation
- Supports both image and video inputs using shared architecture.

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/nikhil150821/Image_Video_Captioning.git
cd Image_Video_Captioning
```

---

### 2ï¸âƒ£ Backend Setup (FastAPI)
```bash
cd backend
pip install -r requirements.txt
# or install manually
pip install fastapi uvicorn sqlalchemy python-multipart opencv-python torch torchvision
uvicorn main:app --reload
```
FastAPI will run at: [http://localhost:8000](http://localhost:8000)

---

### 3ï¸âƒ£ Frontend Setup (React + Vite)
```bash
cd frontend
npm install
npm run dev
```
React frontend will run at: [http://localhost:5173](http://localhost:5173)

---

### 4ï¸âƒ£ Model Training (Optional - already trained)
Inside `/model`, youâ€™ll find three Jupyter Notebooks:
- `image_data_processing.ipynb`: Prepares image data (Flickr8k)
- `video_data_processing.ipynb`: Prepares video data (MSR-VTT)
- `unified_model_training.ipynb`: Trains the shared ResNet50 + LSTM model

---

## ğŸ’¡ Features

- Upload **image** or **video**
- Real-time preview with dimension fitting
- Animated loading screen (â³ flip)
- Redirect to `/predict` with content & caption
- Stores caption data in SQLite
- Clean UI with header, footer, error page

---

## ğŸ“¦ Datasets Used

- **Flickr8k** â€” for image captioning
- **MSR-VTT** â€” for video captioning (frame-based)

---

## ğŸ Demo (Local)

1. Run backend with:
```bash
uvicorn main:app --reload
```

2. Run frontend:
```bash
npm run dev
```

3. Open: [http://localhost:5173](http://localhost:5173)
   - Upload image/video â†’ See preview â†’ Click "Predict" â†’ Get caption.

---

## ğŸ“Œ TODO (Optional Improvements)
- Add authentication & user history
- Add drag-and-drop upload
- Deploy to Vercel + Railway or Render

---

## ğŸ§‘â€ğŸ’» Author

**Nikhil**  
B.Tech CSE - Data Analytics  
GitHub: [@nikhil150821](https://github.com/nikhil150821)

---
